{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "83858320",
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import sys\n",
                "import os\n",
                "sys.path.append(os.path.abspath(\"..\"))\n",
                "\n",
                "import pandas as pd\n",
                "import polars as pl\n",
                "from datetime import datetime\n",
                "import requests\n",
                "\n",
                "from shared.poly_utils import get_markets, PLATFORM_WALLETS  # updated import\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d67ed3d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Polars display prefs\n",
                "pl.Config.set_tbl_rows(25)\n",
                "pl.Config.set_tbl_cols(-1)\n",
                "_ = pl.Config.set_tbl_width_chars(1000)\n",
                "\n",
                "# Paths (relative to analysis/ folder)\n",
                "LOC = \"../\"\n",
                "\n",
                "# Cutoffs / knobs\n",
                "RECENCY_CUTOFF_STR = \"2025-10-01\"   # filter traders whose last market activity is after this date\n",
                "MIN_MARKETS_TRADED = 300            # require enough breadth\n",
                "BIG_WIN_THRESH = 70.0               # percent change considered a \"big win\"\n",
                "MIN_BIG_WINS = 0                    # optionally require some minimum number of big wins to qualify (set >0 to enforce)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "53288874",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load markets from parquet directory\n",
                "markets_df = get_markets(LOC + \"markets_partitioned\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "95af4af2",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pl.scan_parquet(LOC + \"processed/trades/**/*.parquet\").collect(streaming=True)\n",
                "\n",
                "# Ensure timestamp type (parquet usually preserves it, but casting is safe)\n",
                "df = df.with_columns(pl.col(\"timestamp\").cast(pl.Datetime).alias(\"timestamp\"))\n",
                "\n",
                "# Compute latest price per (market_id, nonusdc_side), clamped to [0,1] at the extremes\n",
                "df = df.with_columns(\n",
                "    pl.col(\"price\")\n",
                "      .sort_by(\"timestamp\")\n",
                "      .last()\n",
                "      .over([\"market_id\", \"nonusdc_side\"])\n",
                "      .alias(\"last_price\")\n",
                ")\n",
                "df = df.with_columns(\n",
                "    last_price=(\n",
                "        pl.when(pl.col(\"last_price\") > 0.98).then(pl.lit(1.0))\n",
                "         .when(pl.col(\"last_price\") < 0.02).then(pl.lit(0.0))\n",
                "         .otherwise(pl.col(\"last_price\"))\n",
                "    )\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c37f968c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# %% ----------------------- Leaderboard pull -----------------------\n",
                "def get_polymarket_leaderboard(top_n=500):\n",
                "    \"\"\"\n",
                "    Fetch Polymarket leaderboard data in batches of 50.\n",
                "    Returns a pandas.DataFrame with fields incl. 'user_id' and 'user_name'.\n",
                "    \"\"\"\n",
                "    all_data = []\n",
                "    limit = 50\n",
                "    for offset in range(0, top_n, limit):\n",
                "        url = f\"https://data-api.polymarket.com/leaderboard?timePeriod=all&orderBy=PNL&limit={limit}&offset={offset}\"\n",
                "        res = requests.get(url, timeout=30)\n",
                "        res.raise_for_status()\n",
                "        all_data.extend(res.json())\n",
                "    return pd.DataFrame(all_data)\n",
                "\n",
                "top_n = get_polymarket_leaderboard(500)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "184f882b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# %% ----------------------- Per-trader metrics helpers -----------------------\n",
                "def get_metrics(wallet_address: str) -> pl.DataFrame:\n",
                "    \"\"\"\n",
                "    Build side-level metrics for a single wallet, then compute per-side PnL pieces and VWAPs.\n",
                "    \"\"\"\n",
                "    global df, markets_df\n",
                "\n",
                "    trader_df = df.filter(pl.col(\"maker\") == wallet_address)\n",
                "    if trader_df.height == 0:\n",
                "        # Empty frame with expected schema so downstream doesn't explode\n",
                "        return pl.DataFrame(\n",
                "            {\n",
                "                \"market_id\": pl.Series([], pl.Utf8),\n",
                "                \"side\": pl.Series([], pl.Utf8),\n",
                "                \"trades\": pl.Series([], pl.Int64),\n",
                "                \"avg_buy_price\": pl.Series([], pl.Float64),\n",
                "                \"avg_sold_price_only\": pl.Series([], pl.Float64),\n",
                "                \"avg_sell_price\": pl.Series([], pl.Float64),\n",
                "                \"last_price\": pl.Series([], pl.Float64),\n",
                "                \"total_pnl_usd\": pl.Series([], pl.Float64),\n",
                "                \"last_trade_ts\": pl.Series([], pl.Datetime),\n",
                "                \"buy_usd\": pl.Series([], pl.Float64),\n",
                "                \"sell_usd\": pl.Series([], pl.Float64),\n",
                "                \"buy_tokens\": pl.Series([], pl.Float64),\n",
                "                \"sell_tokens\": pl.Series([], pl.Float64),\n",
                "                \"buy_notional\": pl.Series([], pl.Float64),\n",
                "                \"sell_notional\": pl.Series([], pl.Float64),\n",
                "                \"question\": pl.Series([], pl.Utf8),\n",
                "            }\n",
                "        )\n",
                "\n",
                "    trader_df = trader_df.select(\n",
                "        \"timestamp\", \"market_id\", \"maker\", \"taker\", \"maker_direction\",\n",
                "        \"nonusdc_side\", \"price\", \"token_amount\", \"usd_amount\",\n",
                "        \"transactionHash\", \"last_price\"\n",
                "    ).rename({\"maker_direction\": \"direction\", \"nonusdc_side\": \"side\"})\n",
                "\n",
                "    metrics_df = (\n",
                "        trader_df\n",
                "        .group_by([\"market_id\", \"side\"])\n",
                "        .agg(\n",
                "            # USD volumes\n",
                "            (pl.when(pl.col(\"direction\") == \"BUY\").then(pl.col(\"usd_amount\")).otherwise(0.0)).sum().alias(\"buy_usd\"),\n",
                "            (pl.when(pl.col(\"direction\") == \"SELL\").then(pl.col(\"usd_amount\")).otherwise(0.0)).sum().alias(\"sell_usd\"),\n",
                "\n",
                "            # Token volumes\n",
                "            (pl.when(pl.col(\"direction\") == \"BUY\").then(pl.col(\"token_amount\")).otherwise(0.0)).sum().alias(\"buy_tokens\"),\n",
                "            (pl.when(pl.col(\"direction\") == \"SELL\").then(pl.col(\"token_amount\")).otherwise(0.0)).sum().alias(\"sell_tokens\"),\n",
                "\n",
                "            # Notionals\n",
                "            (pl.when(pl.col(\"direction\") == \"BUY\").then(pl.col(\"price\") * pl.col(\"token_amount\")).otherwise(0.0)).sum().alias(\"buy_notional\"),\n",
                "            (pl.when(pl.col(\"direction\") == \"SELL\").then(pl.col(\"price\") * pl.col(\"token_amount\")).otherwise(0.0)).sum().alias(\"sell_notional\"),\n",
                "\n",
                "            pl.col(\"timestamp\").max().alias(\"last_trade_ts\"),\n",
                "            pl.len().alias(\"trades\"),\n",
                "            pl.col(\"last_price\").last().alias(\"last_price\"),\n",
                "        )\n",
                "        # PnL pieces\n",
                "        .with_columns(\n",
                "            (pl.col(\"sell_usd\") - pl.col(\"buy_usd\")).alias(\"cash_pnl_usd\"),\n",
                "            (pl.col(\"buy_tokens\") - pl.col(\"sell_tokens\")).alias(\"inventory_tokens\"),\n",
                "        )\n",
                "        .with_columns(\n",
                "            (pl.col(\"inventory_tokens\") * pl.col(\"last_price\")).alias(\"unrealized_usd\"),\n",
                "        )\n",
                "        # Then create total_pnl_usd using it\n",
                "        .with_columns(\n",
                "            (pl.col(\"cash_pnl_usd\") + pl.col(\"unrealized_usd\")).alias(\"total_pnl_usd\"),\n",
                "        )\n",
                "        # VWAPs\n",
                "        .with_columns(\n",
                "            pl.when(pl.col(\"buy_tokens\") > 0)\n",
                "              .then(pl.col(\"buy_notional\") / pl.col(\"buy_tokens\"))\n",
                "              .otherwise(None)\n",
                "              .alias(\"avg_buy_price\"),\n",
                "            pl.when(pl.col(\"sell_tokens\") > 0)\n",
                "              .then(pl.col(\"sell_notional\") / pl.col(\"sell_tokens\"))\n",
                "              .otherwise(None)\n",
                "              .alias(\"avg_sold_price_only\"),\n",
                "        )\n",
                "        # Blended exit if closed now at last_price\n",
                "        .with_columns(\n",
                "            (pl.col(\"sell_tokens\") + pl.col(\"inventory_tokens\")).alias(\"effective_exit_tokens\"),\n",
                "            (pl.col(\"sell_notional\") + pl.col(\"inventory_tokens\") * pl.col(\"last_price\")).alias(\"effective_exit_notional\"),\n",
                "        )\n",
                "        .with_columns(\n",
                "            pl.when(pl.col(\"effective_exit_tokens\") > 0)\n",
                "              .then(pl.col(\"effective_exit_notional\") / pl.col(\"effective_exit_tokens\"))\n",
                "              .otherwise(None)\n",
                "              .alias(\"avg_sell_price\")\n",
                "        )\n",
                "        .select(\n",
                "            \"market_id\", \"side\", \"trades\",\n",
                "            \"avg_buy_price\", \"avg_sold_price_only\", \"avg_sell_price\",\n",
                "            \"last_price\", \"total_pnl_usd\",\n",
                "            \"last_trade_ts\",\n",
                "            \"buy_usd\", \"sell_usd\",\n",
                "            \"buy_tokens\", \"sell_tokens\",\n",
                "            \"buy_notional\", \"sell_notional\",\n",
                "        )\n",
                "        .sort([\"market_id\", \"side\"])\n",
                "    )\n",
                "\n",
                "    # attach question text & compute pct_change at side level (for reference)\n",
                "    metrics_df = metrics_df.join(\n",
                "        markets_df[[\"id\", \"question\"]],\n",
                "        left_on=\"market_id\", right_on=\"id\", how=\"left\"\n",
                "    ).drop(\"id\")\n",
                "\n",
                "    metrics_df = metrics_df.with_columns(\n",
                "        (((pl.col('avg_sell_price') - pl.col('avg_buy_price')) / pl.col('avg_buy_price')) * 100)\n",
                "        .alias('pct_change')\n",
                "    )\n",
                "\n",
                "    # remove orphaned market rows\n",
                "    metrics_df = metrics_df.drop_nulls(subset=[\"market_id\"])\n",
                "    return metrics_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03111754",
            "metadata": {},
            "outputs": [],
            "source": [
                "def combine_market_pct(metrics_df: pl.DataFrame) -> pl.DataFrame:\n",
                "    \"\"\"\n",
                "    Collapse (market_id, side) -> (market_id) by taking a buy-USD-weighted average\n",
                "    of pct_change across sides. Also sum PnL/volumes and keep last_trade_ts (max).\n",
                "    \"\"\"\n",
                "    if metrics_df.height == 0:\n",
                "        return pl.DataFrame(\n",
                "            {\n",
                "                \"market_id\": pl.Series([], pl.Utf8),\n",
                "                \"question\": pl.Series([], pl.Utf8),\n",
                "                \"trades\": pl.Series([], pl.Int64),\n",
                "                \"pct_change_combined\": pl.Series([], pl.Float64),\n",
                "                \"total_pnl_usd\": pl.Series([], pl.Float64),\n",
                "                \"buy_usd_total\": pl.Series([], pl.Float64),\n",
                "                \"sell_usd_total\": pl.Series([], pl.Float64),\n",
                "                \"last_trade_ts\": pl.Series([], pl.Datetime),\n",
                "            }\n",
                "        )\n",
                "\n",
                "    tmp = (\n",
                "        metrics_df\n",
                "        .with_columns(\n",
                "            pl.when(pl.col(\"pct_change\").is_not_null()).then(pl.col(\"buy_usd\")).otherwise(0.0).alias(\"weight_usd\"),\n",
                "            (pl.col(\"pct_change\") * pl.col(\"buy_usd\")).fill_null(0.0).alias(\"num_pct_x_usd\"),\n",
                "        )\n",
                "        .group_by(\"market_id\")\n",
                "        .agg(\n",
                "            pl.col(\"question\").first().alias(\"question\"),\n",
                "            pl.col(\"trades\").sum().alias(\"trades\"),\n",
                "            pl.col(\"total_pnl_usd\").sum().alias(\"total_pnl_usd\"),\n",
                "            pl.col(\"buy_usd\").sum().alias(\"buy_usd_total\"),\n",
                "            pl.col(\"sell_usd\").sum().alias(\"sell_usd_total\"),\n",
                "            pl.col(\"num_pct_x_usd\").sum().alias(\"num_pct_x_usd\"),\n",
                "            pl.col(\"weight_usd\").sum().alias(\"den_usd\"),\n",
                "            pl.col(\"last_trade_ts\").max().alias(\"last_trade_ts\"),\n",
                "        )\n",
                "        .with_columns(\n",
                "            pl.when(pl.col(\"den_usd\") > 0)\n",
                "              .then(pl.col(\"num_pct_x_usd\") / pl.col(\"den_usd\"))\n",
                "              .otherwise(None)\n",
                "              .alias(\"pct_change_combined\")\n",
                "        )\n",
                "        .select(\n",
                "            \"market_id\", \"question\", \"trades\",\n",
                "            \"pct_change_combined\",\n",
                "            \"total_pnl_usd\", \"buy_usd_total\", \"sell_usd_total\",\n",
                "            \"last_trade_ts\",\n",
                "        )\n",
                "        .sort(\"market_id\")\n",
                "    )\n",
                "    return tmp\n",
                "\n",
                "\n",
                "def _safe_median(series: pl.Series):\n",
                "    return series.median() if series.len() > 0 else None\n",
                "\n",
                "\n",
                "def compute_trader_metrics(wallet_address: str) -> dict:\n",
                "    \"\"\"\n",
                "    Robust per-trader stats based on per-market outcomes (one row per market).\n",
                "    - win_rate\n",
                "    - big_win_rate_overall (>= BIG_WIN_THRESH)\n",
                "    - big_win_rate_among_wins\n",
                "    - median_win_pct / median_loss_pct\n",
                "    - median_win_usd / median_loss_usd\n",
                "    - total_pnl_usd, markets_traded, last_trade\n",
                "    \"\"\"\n",
                "    metrics_df = get_metrics(wallet_address)\n",
                "    c_df = combine_market_pct(metrics_df).rename({\"pct_change_combined\": \"pct_change\"})\n",
                "\n",
                "    n = c_df.height\n",
                "    if n == 0:\n",
                "        return {\n",
                "            \"wallet\": wallet_address, \"markets_traded\": 0, \"last_trade\": None,\n",
                "            \"win_rate\": None, \"big_win_rate_overall\": None, \"big_win_rate_among_wins\": None,\n",
                "            \"median_win_pct\": None, \"median_loss_pct\": None,\n",
                "            \"median_win_usd\": None, \"median_loss_usd\": None,\n",
                "            \"total_pnl_usd\": 0.0, \"big_wins_count\": 0\n",
                "        }\n",
                "\n",
                "    last_trade = c_df[\"last_trade_ts\"].max()\n",
                "    wins   = c_df.filter(pl.col(\"total_pnl_usd\") > 0)\n",
                "    losses = c_df.filter(pl.col(\"total_pnl_usd\") <= 0)\n",
                "\n",
                "    w = wins.height\n",
                "    l = losses.height\n",
                "\n",
                "    big_wins = wins.filter(pl.col(\"pct_change\") >= BIG_WIN_THRESH)\n",
                "    bw = big_wins.height\n",
                "\n",
                "    win_rate = w / n if n > 0 else None\n",
                "    big_win_rate_overall = bw / n if n > 0 else None\n",
                "    big_win_rate_among_wins = (bw / w) if w > 0 else None\n",
                "\n",
                "    median_win_pct  = _safe_median(wins[\"pct_change\"]) if w > 0 else None\n",
                "    median_loss_pct = _safe_median(losses[\"pct_change\"]) if l > 0 else None\n",
                "    median_win_usd  = _safe_median(wins[\"total_pnl_usd\"]) if w > 0 else None\n",
                "    median_loss_usd = _safe_median(losses[\"total_pnl_usd\"]) if l > 0 else None\n",
                "\n",
                "    total_pnl_usd   = float(c_df[\"total_pnl_usd\"].sum())\n",
                "\n",
                "    return {\n",
                "        \"wallet\": wallet_address,\n",
                "        \"markets_traded\": n,\n",
                "        \"last_trade\": last_trade,\n",
                "        \"win_rate\": win_rate,\n",
                "        \"big_win_rate_overall\": big_win_rate_overall,\n",
                "        \"big_win_rate_among_wins\": big_win_rate_among_wins,\n",
                "        \"median_win_pct\": median_win_pct,\n",
                "        \"median_loss_pct\": median_loss_pct,\n",
                "        \"median_win_usd\": median_win_usd,\n",
                "        \"median_loss_usd\": median_loss_usd,\n",
                "        \"total_pnl_usd\": total_pnl_usd,\n",
                "        \"big_wins_count\": bw,\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "73a51dbd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# %% ----------------------- Run over leaderboard & rank -----------------------\n",
                "rows = []\n",
                "for _, r in top_n.iterrows():\n",
                "    stats = compute_trader_metrics(wallet_address=r[\"user_id\"])\n",
                "    stats[\"user_name\"] = r.get(\"user_name\", None)\n",
                "    print(stats)\n",
                "\n",
                "    rows.append(stats)\n",
                "\n",
                "rank_df = pd.DataFrame(rows)\n",
                "\n",
                "# Normalize & filter\n",
                "rank_df[\"last_trade\"] = pd.to_datetime(rank_df[\"last_trade\"])\n",
                "recency_cutoff = pd.to_datetime(RECENCY_CUTOFF_STR)\n",
                "\n",
                "# Core filters\n",
                "rank_df = rank_df[\n",
                "    (rank_df[\"markets_traded\"] >= MIN_MARKETS_TRADED) &\n",
                "    (rank_df[\"last_trade\"] > recency_cutoff) &\n",
                "    (rank_df[\"win_rate\"].notna())\n",
                "].copy()\n",
                "\n",
                "# Optional: require at least N big wins\n",
                "if MIN_BIG_WINS > 0:\n",
                "    rank_df = rank_df[rank_df[\"big_wins_count\"] >= MIN_BIG_WINS].copy()\n",
                "\n",
                "# Convenient percent display columns\n",
                "rank_df[\"win_rate_pct\"] = (rank_df[\"win_rate\"] * 100).round(2)\n",
                "rank_df[\"big_win_rate_overall_pct\"] = (rank_df[\"big_win_rate_overall\"] * 100).round(2)\n",
                "rank_df[\"big_win_rate_among_wins_pct\"] = (rank_df[\"big_win_rate_among_wins\"] * 100).round(2)\n",
                "\n",
                "# Sort to emphasize consistent big winners (then typical size, then $ impact)\n",
                "rank_df = rank_df.sort_values(\n",
                "    by=[\n",
                "        \"big_win_rate_among_wins\",  # consistency of landing big wins when they do win\n",
                "        \"median_win_pct\",           # typical magnitude of wins (pct)\n",
                "        \"total_pnl_usd\"             # economic impact\n",
                "    ],\n",
                "    ascending=[False, False, False]\n",
                ")\n",
                "\n",
                "# Output: Top 50 table\n",
                "top50_cols = [\n",
                "    \"user_name\", \"wallet\", \"markets_traded\", \"last_trade\",\n",
                "    \"win_rate_pct\", \"big_win_rate_overall_pct\", \"big_win_rate_among_wins_pct\",\n",
                "    \"median_win_pct\", \"median_loss_pct\",\n",
                "    \"median_win_usd\", \"median_loss_usd\",\n",
                "    \"big_wins_count\",\n",
                "    \"total_pnl_usd\"\n",
                "]\n",
                "top50 = rank_df[top50_cols].head(50)\n",
                "top50.reset_index(drop=True, inplace=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c7ce8bfd",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48415df9",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}